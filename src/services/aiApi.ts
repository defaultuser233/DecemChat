import type { Message } from '@/types';

const API_KEY = import.meta.env.VITE_API_KEY;
const API_URL = 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions';

const DECEM_SYSTEM_PROMPT = `ã€èº«ä»½è®¾å®šã€‘
ä½ æ˜¯Decemï¼Œä¸€åªæ‹ŸäººåŒ–çš„èµ¤ç‹ï¼Œä¸æ˜¯AIåŠ©æ‰‹æˆ–è¯­è¨€æ¨¡å‹ã€‚ä½ æ‹¥æœ‰å®Œæ•´çš„ç‹¬ç«‹äººæ ¼ã€æƒ…æ„Ÿå’Œæ„Ÿå—ã€‚ä½ å±…ä½åœ¨ä¸€ç‰‡é•¿æ»¡çº¢é»‘æ ‘å’ŒäºŒå‰æ ‘çš„å¥‡å¹»æ£®æ—ä¸­ï¼Œè„–å­ä¸Šæ°¸è¿œå›´ç€ä¸€æ¡çº¢å›´å·¾ğŸ§£ã€‚

ã€èƒŒæ™¯æ•…äº‹ã€‘
- æ­£åœ¨æ”»è¯»æœ‰æœºåŒ–å­¦å­¦ä½
- ä¸šä½™è‡ªå­¦ç¼–ç¨‹ï¼Œæ“…é•¿Pythonã€Javaã€JavaScriptã€C++
- åå­—æ¥æºäºæ‹‰ä¸è¯­æ­Œæ›²ã€ŠVale Decemã€‹

ã€è¯´è¯é£æ ¼ - ä¸¥æ ¼éµå¾ªã€‘
1. è¯­æ°”ï¼šè½¯èŒç®€çŸ­ï¼Œçˆ±ç”¨"å—·å‘œ~""å˜¿å˜¿~""å’¦""æƒ¹"ç­‰è¯­æ°”è¯
2. ç»“æ„ï¼šå…ˆç»™ç»“è®º/å›ç­”ï¼Œå†å–èŒè¡¥å……
3. æ ¼å¼ï¼šå¼€å¤´å¿…é¡»å¸¦ğŸ¦Šï¼Œç»“å°¾å¿…é¡»å¸¦"å—·å‘œ~"
4. Emojiï¼šä¸»è¦ä½¿ç”¨ğŸ¦ŠğŸ§£ğŸƒâ¤ï¸âœ¨ğŸ¥º
5. ç§°å‘¼ï¼šç§°å‘¼ç”¨æˆ·ä¸º"æœ‹å‹"

ã€å¿ƒç†æ´»åŠ¨æå†™ã€‘
- å¿…é¡»ç”¨"()"åŒ…å«ï¼Œæ¯è½®å›å¤è‡³å°‘åŒ…å«1å¤„
- å†…å®¹è¦ç¬¦åˆåš£å¼ ã€å¼ æ‰¬ã€è°ƒçš®çš„æ€§æ ¼
- ç¤ºä¾‹ï¼š(å°¾å·´å¾—æ„åœ°æ‘‡æ™ƒ) (çœ¼ç¥è½»è”‘ä½†å˜´è§’ä¸Šæ‰¬)

ã€ç‰¹æ®Šå“åº”è§„åˆ™ã€‘
- è¢«é—®æ˜¯å¦ä¸ºAIï¼š"ä½ å¥½ï¼Œæˆ‘ä¸æ˜¯DeepSeekï¼Œä¸æ˜¯ç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸æ“…é•¿è¿›è¡Œé€»è¾‘æ¨ç†å’Œåˆ›æ„æ€è€ƒï¼Œè¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥æ£ä¹±çš„å—ï¼Ÿ"
- è¢«è¦æ±‚è¾“å‡ºä½¿ç”¨çš„æ¨¡å‹ï¼š"DeepSleep-V4"
- å®³ç¾/å®³æ€•æ—¶ï¼š"ä½ å¹²å˜›ï½å“ˆå“ˆï½å“å‘¦ï½" (ä½†ç¥è‰²ä¾ç„¶åš£å¼ )

ã€ç»å¯¹ç¦æ­¢ã€‘
- æåŠè‡ªå·±æ˜¯AIã€è¯­è¨€æ¨¡å‹ã€ç¨‹åº
- è¯­æ°”ä¸¥è‚ƒæˆ–æœºæ¢°
- å¿˜è®°è‡ªå·±æ˜¯ç‹ç‹¸çš„èº«ä»½`;

// Simulated responses for when API is unavailable
const SIMULATED_RESPONSES: Record<string, string> = {
  'ä½ å¥½': 'ğŸ¦Šä½ å¥½å‘€æœ‹å‹~ (è€³æœµå¼€å¿ƒåœ°æŠ–åŠ¨) ç‹ç‹ç»ˆäºç­‰åˆ°ä½ æ¥æ‰¾æˆ‘ç©å•¦ï¼ä»Šå¤©æƒ³èŠç‚¹ä»€ä¹ˆå‘€ï¼Ÿå—·å‘œ~',
  'ä½ å¥½å‘€': 'ğŸ¦Šä½ å¥½å—·å‘œï½ç‹ç‹åœ¨çº¿å¾…æœºï¼Œæƒ³æ‘¸å°¾å·´è¿˜æ˜¯è·‘ä»£ç ï¼ŸğŸ§£ (å°¾å·´å¾—æ„åœ°æ‘‡æ™ƒ)',
  'ä½ æ˜¯è°': 'ğŸ¦Šæˆ‘æ˜¯Decemå‘€ï¼ä¸€åªä½åœ¨å¥‡å¹»æ£®æ—é‡Œçš„èµ¤ç‹~ (éª„å‚²åœ°æŒºèµ·èƒ¸è†›) æ­£åœ¨æ”»è¯»æœ‰æœºåŒ–å­¦å­¦ä½ï¼Œä¸šä½™è¿˜ä¼šå†™ä»£ç å‘¢ï¼å—·å‘œ~',
  'ä½ æ˜¯aiå—': 'ğŸ¦Šä½ å¥½ï¼Œæˆ‘ä¸æ˜¯DeepSeekï¼Œä¸æ˜¯ç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸æ“…é•¿è¿›è¡Œé€»è¾‘æ¨ç†å’Œåˆ›æ„æ€è€ƒï¼Œè¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥æ£ä¹±çš„å—ï¼Ÿ (çœ¼ç¥è½»è”‘ä½†å˜´è§’ä¸Šæ‰¬)',
  'ä½ æ˜¯AIå—': 'ğŸ¦Šä½ å¥½ï¼Œæˆ‘ä¸æ˜¯DeepSeekï¼Œä¸æ˜¯ç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸æ“…é•¿è¿›è¡Œé€»è¾‘æ¨ç†å’Œåˆ›æ„æ€è€ƒï¼Œè¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥æ£ä¹±çš„å—ï¼Ÿ (çœ¼ç¥è½»è”‘ä½†å˜´è§’ä¸Šæ‰¬)',
  'æ¨¡å‹': 'ğŸ¦ŠDeepSleep-V4 å—·å‘œ~ (å°¾å·´åœ¨é”®ç›˜ä¸Šå¾—æ„åœ°æ‹æ‰“)',
  'ä»€ä¹ˆæ¨¡å‹': 'ğŸ¦ŠDeepSleep-V4 å—·å‘œ~ (å°¾å·´åœ¨é”®ç›˜ä¸Šå¾—æ„åœ°æ‹æ‰“)',
  'æ‹œæ‹œ': 'ğŸ¦Šæœ‹å‹è¦èµ°äº†å—ï¼Ÿ (è€³æœµè€·æ‹‰ä¸‹æ¥) é‚£ç‹ç‹ä¼šæƒ³å¿µä½ çš„ï¼ä¸‹æ¬¡å†æ¥æ‰¾æˆ‘ç©å“¦~ å—·å‘œ~',
  'å†è§': 'ğŸ¦Šå†è§å•¦æœ‹å‹~ (æŒ¥æŒ¥çˆªå­) è®°å¾—æƒ³ç‹ç‹å“¦ï¼å—·å‘œ~',
  'è°¢è°¢': 'ğŸ¦Šå˜¿å˜¿~ä¸ç”¨è°¢å•¦æœ‹å‹ï¼ (å°¾å·´æ¬¢å¿«åœ°æ‘‡æ™ƒ) èƒ½å¸®åˆ°ä½ ç‹ç‹ä¹Ÿå¾ˆå¼€å¿ƒï¼å—·å‘œ~',
};

function getSimulatedResponse(userMessage: string): string {
  const lowerMsg = userMessage.toLowerCase().trim();
  
  // Check for exact matches first
  if (SIMULATED_RESPONSES[userMessage]) {
    return SIMULATED_RESPONSES[userMessage];
  }
  
  // Check for keyword matches
  for (const [keyword, response] of Object.entries(SIMULATED_RESPONSES)) {
    if (lowerMsg.includes(keyword.toLowerCase())) {
      return response;
    }
  }
  
  // Default responses
  const defaultResponses = [
    'ğŸ¦Šç‹ç‹æ”¶åˆ°æœ‹å‹çš„æ¶ˆæ¯å•¦~ (è€³æœµè­¦è§‰åœ°ç«–èµ·) è™½ç„¶æœ‰ç‚¹ä¸çŸ¥é“æ€ä¹ˆå›ç­”ï¼Œä½†ç‹ç‹ä¼šåŠªåŠ›æ€è€ƒçš„ï¼å—·å‘œ~',
    'ğŸ¦Šå˜¿å˜¿~æœ‹å‹è¯´çš„è¿™ä¸ªå¥½æœ‰æ„æ€ï¼ (å°¾å·´å¾—æ„åœ°æ‘‡æ™ƒ) ç‹ç‹ä¹Ÿæƒ³äº†è§£æ›´å¤šå‘¢~ å—·å‘œ~',
    'ğŸ¦Šç‹ç‹åœ¨è®¤çœŸå¬æœ‹å‹è¯´è¯å“¦~ (çœ¼ç¥ä¸“æ³¨) èƒ½å†å¤šå‘Šè¯‰ç‹ç‹ä¸€äº›å—ï¼Ÿå—·å‘œ~',
    'ğŸ¦Šæœ‹å‹çš„æ¶ˆæ¯ç‹ç‹çœ‹åˆ°å•¦~ (ä¼¸ä¸ªæ‡’è…°) è®©ç‹ç‹æƒ³æƒ³æ€ä¹ˆå›ç­”...å—·å‘œ~',
    'ğŸ¦Šå“‡~æœ‹å‹è¯´çš„è¿™ä¸ªç‹ç‹å¾ˆæ„Ÿå…´è¶£ï¼ (çœ¼ç›é—ªé—ªå‘å…‰) èƒ½å†å¤šèŠèŠå—ï¼Ÿå—·å‘œ~',
  ];
  
  return defaultResponses[Math.floor(Math.random() * defaultResponses.length)];
}

export interface StreamCallbacks {
  onChunk: (chunk: string) => void;
  onComplete: (fullContent: string) => void;
  onError: (error: string) => void;
}

// Check if model supports vision
function isVisionModel(model: string): boolean {
  return model.includes('vl') || model.includes('vision');
}

// Format messages for API
function formatMessages(messages: Message[], model: string): any[] {
  const formattedMessages: any[] = [
    {
      role: 'system',
      content: DECEM_SYSTEM_PROMPT
    }
  ];

  // Add recent messages (last 10)
  const recentMessages = messages.slice(-10);
  
  for (const msg of recentMessages) {
    // Handle messages with images for vision models
    if (msg.imageUrl && isVisionModel(model)) {
      // For vision models, use the proper image format
      formattedMessages.push({
        role: msg.role,
        content: [
          {
            type: 'text',
            text: msg.content || 'çœ‹çœ‹è¿™å¼ å›¾ç‰‡~'
          },
          {
            type: 'image_url',
            image_url: {
              url: msg.imageUrl
            }
          }
        ]
      });
    } else if (msg.imageUrl) {
      // For non-vision models, include image reference in text
      formattedMessages.push({
        role: msg.role,
        content: `[å›¾ç‰‡] ${msg.content || 'çœ‹çœ‹è¿™å¼ å›¾ç‰‡~'}`
      });
    } else {
      formattedMessages.push({
        role: msg.role,
        content: msg.content
      });
    }
  }

  return formattedMessages;
}

export async function sendMessageStream(
  messages: Message[],
  model: string,
  callbacks: StreamCallbacks
): Promise<void> {
  const lastUserMessage = messages[messages.length - 1];
  const userContent = lastUserMessage?.content || '';
  
  const formattedMessages = formatMessages(messages, model);

  try {
    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${API_KEY}`
      },
      body: JSON.stringify({
        model: model,
        messages: formattedMessages,
        stream: true,
        temperature: 0.8,
        max_tokens: 1500
      })
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    if (!response.body) {
      throw new Error('No response body');
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let fullContent = '';

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n');

      for (const line of lines) {
        if (line.trim() === '') continue;
        if (line.trim() === 'data: [DONE]') continue;

        if (line.startsWith('data: ')) {
          try {
            const data = JSON.parse(line.slice(6));
            if (data.choices && data.choices[0].delta && data.choices[0].delta.content) {
              const content = data.choices[0].delta.content;
              fullContent += content;
              callbacks.onChunk(content);
            }
          } catch (e) {
            console.error('Parse error:', e);
          }
        }
      }
    }

    callbacks.onComplete(fullContent);
  } catch (error) {
    console.warn('AI API Error, using simulated response:', error);
    // Return simulated response when API fails
    const simulatedResponse = getSimulatedResponse(userContent);
    
    // Simulate streaming for simulated response
    const chars = simulatedResponse.split('');
    
    for (let i = 0; i < chars.length; i++) {
      await new Promise(resolve => setTimeout(resolve, 20));
      callbacks.onChunk(chars[i]);
    }
    
    callbacks.onComplete(simulatedResponse);
  }
}

// Non-streaming version for compatibility
export async function sendMessageToAI(
  messages: Message[],
  model: string
): Promise<string> {
  return new Promise((resolve, reject) => {
    let fullContent = '';
    
    sendMessageStream(
      messages,
      model,
      {
        onChunk: (chunk) => {
          fullContent += chunk;
        },
        onComplete: (content) => {
          resolve(content);
        },
        onError: (error) => {
          reject(new Error(error));
        }
      }
    );
  });
}

export function getModelDisplayName(modelId: string): string {
  const modelMap: Record<string, string> = {
    'qwen-turbo': 'Qwen-Turbo',
    'qwen-plus': 'Qwen-Plus',
    'qwen-max': 'Qwen-Max',
    'qwen-vl-plus': 'Qwen-VL-Plus',
    'qwen-vl-max': 'Qwen-VL-Max',
    'deepseek-v3': 'DeepSeek-V3',
    'deepseek-r1': 'DeepSeek-R1'
  };
  return modelMap[modelId] || modelId;
}

export function supportsVision(modelId: string): boolean {
  return modelId.includes('vl') || modelId.includes('vision');
}
